name: Daily Food Price Scraper

on:
  schedule:
    # Run every day at 8:30 AM Jakarta time (1:30 AM UTC)
    - cron: '30 1 * * *'
  
  workflow_dispatch:  # Allow manual trigger from GitHub UI
    inputs:
      days_back:
        description: 'Days to scrape back (optional)'
        required: false
        default: '7'

jobs:
  scrape-and-notify:
    runs-on: ubuntu-latest
    
    steps:
    # Step 1: Checkout code
    - name: Checkout repository
      uses: actions/checkout@v4  # ← Updated from v3
    
    # Step 2: Setup Python
    - name: Set up Python 3.10
      uses: actions/setup-python@v5  # ← Updated from v4
      with:
        python-version: '3.10'
        cache: 'pip'  # Cache pip packages for faster builds
    
    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    # Step 4: Run daily scraper
    - name: Run daily scraper
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
        EMAIL_APP_PASSWORD: ${{ secrets.EMAIL_APP_PASSWORD }}
        ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
      run: |
        echo "Starting daily scraper..."
        python daily_scraper.py
      continue-on-error: true  # Continue to notification even if scraper fails
    
    # Step 5: Send notification on success
    - name: Notify success
      if: success()
      env:
        EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
        EMAIL_APP_PASSWORD: ${{ secrets.EMAIL_APP_PASSWORD }}
        ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
      run: |
        python -c "
        from src.utils.notifications import send_success_email
        send_success_email('Daily scrape completed successfully')
        "
    
    # Step 6: Send notification on failure
    - name: Notify failure
      if: failure()
      env:
        EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
        EMAIL_APP_PASSWORD: ${{ secrets.EMAIL_APP_PASSWORD }}
        ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
      run: |
        python -c "
        from src.utils.notifications import send_failure_email
        send_failure_email('Daily scrape failed. Check GitHub Actions logs.')
        "
    
    # Step 7: Upload logs on failure
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v4  # ← Updated from v3
      with:
        name: scraper-logs
        path: '*.log'
        retention-days: 7
        compression-level: 6  # New in v4